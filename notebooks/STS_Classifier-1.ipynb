{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os, sys, inspect\r\n",
    "import glob\r\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sklearn\r\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler  \r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import plot_confusion_matrix\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision import datasets, transforms\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "from torch.utils.data import Dataset, Subset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\r\n",
    "parentdir = os.path.dirname(currentdir)\r\n",
    "sys.path.append(parentdir)\r\n",
    "from nmdr.classifier.models import ConvNet1D\r\n",
    "from nmdr.classifier.datasets import STSDataset\r\n",
    "from nmdr.classifier.run import train, test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# root = 'G:\\\\Research\\\\AI_STM\\\\gpspec\\\\dpath\\\\train\\\\'\r\n",
    "# os.listdir(root)\r\n",
    "# paths = glob.glob(os.path.join(root, \"**/*.npy\"), recursive = True)\r\n",
    "# paths = np.array(paths)\r\n",
    "# idxs = [1,5,6]\r\n",
    "# x = paths[idxs][0]\r\n",
    "# x[-26:-20]\r\n",
    "p=Path('G:\\\\Research\\\\AI_STM\\\\gpspec\\\\dpath\\\\train\\\\au_fcc\\\\dI_dV00008_Au_3.npy')\r\n",
    "p.parts[-2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Custom Data Loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# class STSDataset(Dataset):\n",
    "#     def __init__(self, data_path, transform=None, target_transform=None):\n",
    "#         # get all filenames in root with filetype .npy\n",
    "#         self.data_root =  os.path.join(data_path, \"**/*.npy\")\n",
    "#         self.data_paths = glob.glob(self.data_root,\n",
    "#                                     recursive = True)\n",
    "#         self.data_paths = np.array(self.data_paths)\n",
    "        \n",
    "#         # get classes from directory structure\n",
    "#         self.targets = os.listdir(data_path)\n",
    "#         self.num_classes = len(self.targets)\n",
    "        \n",
    "#         # get number of samples\n",
    "#         self.n = len(self.data_paths)\n",
    "        \n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "        \n",
    "#         # get filepath using indexes \n",
    "#         sts_path = self.data_paths[idx]\n",
    "        \n",
    "#         # Get sts sample class from path\n",
    "#         label = Path(sts_path).parts[-2]\n",
    "        \n",
    "#         # Convert label to index\n",
    "#         label_i = self.targets.index(label)\n",
    "        \n",
    "#         # Use index to set active bit of onehot vector\n",
    "#         label_onehot = np.zeros(self.num_classes)\n",
    "#         label_onehot[label_i] = 1\n",
    "        \n",
    "#         # Read STS data from disk\n",
    "#         sts = np.load(sts_path)\n",
    "        \n",
    "#         # data has dI/dV and V with shape (2, 1200)\n",
    "#         # only use dI/dV\n",
    "#         sts = sts[0].copy().reshape( 1, -1)\n",
    "        \n",
    "#         if self.transform:\n",
    "#             sts = self.transform(sts)\n",
    "#         if self.target_transform:\n",
    "#             label_onehot = self.target_transform(label_onehot)\n",
    "            \n",
    "#         return torch.tensor(sts, dtype=float),  torch.tensor(label_i, dtype=torch.long)"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Convolutional Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# class ConvNet(nn.Module):\n",
    "\n",
    "#     def __init__(self, n, num_classes, debug=False):\n",
    "#         super().__init__()\n",
    "#         self.debug = debug\n",
    "#         self.num_classes = num_classes\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1,\n",
    "#                                out_channels=64, \n",
    "#                                kernel_size=3, \n",
    "#                                stride=1)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=64,\n",
    "#                        out_channels=128, \n",
    "#                        kernel_size=3, \n",
    "#                        stride=1)\n",
    "#         self.maxpool = nn.MaxPool1d(3, stride=2)\n",
    "#         self.dropout = nn.Dropout(p=0.5)\n",
    "#         self.fc1 = nn.Linear(597, num_classes)\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         if self.debug: print(x.shape)\n",
    "\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         if self.debug: print(x.shape)\n",
    "        \n",
    "#         x = self.maxpool(x)\n",
    "#         if self.debug: print(x.shape)\n",
    "            \n",
    "#         x = self.dropout(x)\n",
    "#         if self.debug: print(x.shape)\n",
    "            \n",
    "#         x = self.fc1(x)\n",
    "#         if self.debug: print(x.shape)\n",
    "        \n",
    "#         # Remove unnecessary dimensions and change shape to match target tensor\n",
    "#         # [BATCH_SIZE, num_classes, 1, 1] --> [BATCH_SIZE,num_classes] to make predicitons\n",
    "# #         output = torch.squeeze(x)\n",
    "#         output = torch.reshape(x, (-1, self.num_classes))\n",
    "#         if self.debug: print(\"output:\\t\", output.shape)\n",
    "\n",
    "#         return x"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def progbar(curr, total, full_progbar, accuracy):\n",
    "#     frac = curr/total\n",
    "#     filled_progbar = round(frac*full_progbar)\n",
    "#     print('\\r', \n",
    "#           '#'*filled_progbar + '-'*(full_progbar-filled_progbar), \n",
    "#           '[{:>7.2%}]'.format(frac), \n",
    "#           'Accuracy: [{:>7.2%}]'.format(accuracy),\n",
    "#           end='')"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def train(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_cats):\n",
    "#     '''\n",
    "#     Trains the model for an epoch and optimizes it.\n",
    "#     model: The model to train. Should already be in correct device.\n",
    "#     device: 'cuda' or 'cpu'.\n",
    "#     train_loader: dataloader for training samples.\n",
    "#     optimizer: optimizer to use for model parameter updates.\n",
    "#     criterion: used to compute loss for prediction and target \n",
    "#     epoch: Current epoch to train for.\n",
    "#     batch_size: Batch size to be used.\n",
    "#     '''\n",
    "    \n",
    "#     # Set model to train mode before each epoch\n",
    "#     model.train()\n",
    "    \n",
    "#     # Empty list to store losses \n",
    "#     losses = []\n",
    "#     correct = 0\n",
    "    \n",
    "#     # Iterate over entire training samples (1 epoch)\n",
    "#     for batch_idx, batch_sample in enumerate(train_loader):\n",
    "#         data, target = batch_sample\n",
    "\n",
    "#         # Push data/label to correct device\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "\n",
    "#         # Reset optimizer gradients. Avoids grad accumulation (accumulation used in RNN).\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Do forward pass for current set of data\n",
    "#         output = model(data.float())\n",
    "        \n",
    "#         # Compute loss based on criterion\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         # Computes gradient based on final loss\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Store loss\n",
    "#         losses.append(loss.item())\n",
    "        \n",
    "#         # Optimize model parameters based on learning rate and gradient \n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Get predicted class by rounding \n",
    "#         pred = output.round()\n",
    "#         pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "#         # Count correct predictions overall \n",
    "#         # Get element-wise equality between the preds and the targets for this batch,\n",
    "#         # finally sum the equalities and convert to a python float\n",
    "#         n_equal = pred.eq(target).sum().item()\n",
    "#         correct += n_equal\n",
    "\n",
    "#         # Update progress bar\n",
    "#         batch_accuracy = n_equal / torch.numel(target)\n",
    "#         progbar(batch_idx, len(train_loader), 10, batch_accuracy)\n",
    "    \n",
    "#     train_loss = float(np.mean(losses))\n",
    "#     train_acc = 100. * correct / ((batch_idx+1) * batch_size * num_cats)\n",
    "    \n",
    "#     print('\\nTrain set\\t Average loss: {:.4f}\\t Average Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "#         train_loss, correct, (batch_idx+1) * batch_size * num_cats, train_acc))\n",
    "          \n",
    "#     return train_loss, train_acc"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def test(model, device, test_loader, criterion, num_cats):\n",
    "#     '''\n",
    "#     Tests the model.\n",
    "#     model: The model to train. Should already be in correct device.\n",
    "#     device: 'cuda' or 'cpu'.\n",
    "#     test_loader: dataloader for test samples.\n",
    "#     '''\n",
    "    \n",
    "#     # Set model to eval mode to notify all layers.\n",
    "#     model.eval()\n",
    "    \n",
    "#     losses = []\n",
    "#     correct = 0\n",
    "    \n",
    "#     # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, sample in enumerate(test_loader):\n",
    "#             data, target = sample\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "                \n",
    "#             # Predict for data by doing forward pass\n",
    "#             output = model(data.float())\n",
    "            \n",
    "#             # Compute loss based on same criterion as training\n",
    "#             loss = criterion(output, target)\n",
    "\n",
    "#             # Append loss to overall test loss\n",
    "#             losses.append(loss.item())\n",
    "\n",
    "#             # Get predicted class by rounding \n",
    "#             pred = output.round()\n",
    "#             pred = torch.argmax(pred, dim=1)\n",
    "            \n",
    "#             # Count correct predictions overall \n",
    "#             # Get element-wise equality between the preds and the targets for this batch,\n",
    "#             # finally sum the equalities and convert to a std python float\n",
    "#             n_equal = pred.eq(target).sum().item()\n",
    "#             correct += n_equal\n",
    "\n",
    "#     test_loss = float(np.mean(losses))\n",
    "#     test_acc = (100. * correct) / (len(test_loader.dataset) * num_cats)\n",
    "#     print('Test set\\t Average loss: {:.4f}\\t Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset) * num_cats, test_acc))\n",
    "    \n",
    "#     return test_loss, test_acc"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check if cuda is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Set proper device based on cuda availability \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Torch device selected: \", device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_path = 'G:\\\\Research\\\\AI_STM\\\\gpspec\\\\dpath\\\\'\n",
    "train_path = data_path + 'train\\\\'\n",
    "val_path = data_path + 'validation\\\\'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create train and val subsets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create transformations to apply to each data sample \n",
    "# Can specify variations such as image flip, color flip, random crop, ...\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((1,1200)),\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sts_trainset = STSDataset(data_path=train_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sts_valset = STSDataset(data_path=val_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "idxs = list(range(len(sts_valset)))\n",
    "test_split = 0.4\n",
    "val_idx, test_idx = train_test_split(idxs, test_size=test_split)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(val_idx), len(test_idx))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sts_valset = Subset(sts_valset, val_idx)\n",
    "sts_testset = Subset(sts_valset, test_idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(sts_valset), len(sts_testset))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "# for i in range(len(sts_trainset)):\n",
    "#     sts, label = sts_trainset[i]\n",
    "#     print(i, sts.shape, label)\n",
    "\n",
    "#     ax = plt.subplot(1, 4, i + 1)\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     sample = sts.numpy()\n",
    "#     plt.plot(sample)\n",
    "\n",
    "#     if i == 3:\n",
    "#         plt.show()\n",
    "#         break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing data for training with DataLoaders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_dataloader = DataLoader(sts_trainset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(sts_valset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(sts_testset, batch_size=16, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(train_dataloader), len(val_dataloader), len(test_dataloader))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test iteration through the DataLoader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sts, label = next(iter(train_dataloader))\n",
    "sts_trainset[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(len(test_dataloader))\n",
    "# for x in test_dataloader:\n",
    "#     print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sts, label = next(iter(test_dataloader))\n",
    "# sts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_classes = 4\n",
    "n = len(sts_trainset[0][0])\n",
    "print(f'{num_classes} classes of {n} points')\n",
    "model = ConvNet1D(n=n, num_classes=num_classes, debug=False).to(device)\n",
    "EPOCHS = 100\n",
    "learning_rate = 0.001\n",
    "BATCH_SIZE = 16\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_accuracy = 0.0\n",
    "train_losses = np.zeros(EPOCHS)\n",
    "train_accuracies = np.zeros(EPOCHS)\n",
    "val_losses = np.zeros(EPOCHS)\n",
    "val_accuracies = np.zeros(EPOCHS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    train_loss, train_accuracy = train(model, device, \n",
    "                                           train_dataloader, \n",
    "                                           optimizer, criterion, \n",
    "                                           epoch, BATCH_SIZE, \n",
    "                                           num_classes)\n",
    "    val_loss, val_accuracy = test(model, device, \n",
    "                                    val_dataloader, \n",
    "                                    criterion, num_classes)\n",
    "\n",
    "    # Store epoch metrics in memory\n",
    "    i = epoch - 1\n",
    "    train_losses[i] = train_loss\n",
    "    train_accuracies[i] = train_accuracy\n",
    "    val_losses[i] = val_loss\n",
    "    val_accuracies[i] = val_accuracy\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        \n",
    "# Print final results to console\n",
    "print(\"best accuracy was {:2.2f}\".format(best_accuracy))\n",
    "print(\"Training and evaluation finished\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_metrics(metrics):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    for n, metric in enumerate(['loss', 'accuracy']):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,3,n+1)\n",
    "        plt.plot(metrics[metric], label='Train')\n",
    "        plt.plot(metrics['val_'+metric], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        plt.autoscale()\n",
    "        plt.legend()\n",
    "        plt.title(\"Standardized Data\")\n",
    "        \n",
    "    plt.autoscale()\n",
    "    plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_metrics({\n",
    "    \"loss\": train_losses, \n",
    "    \"accuracy\": train_accuracies, \n",
    "    \"val_loss\": val_losses, \n",
    "    \"val_accuracy\": val_accuracies\n",
    "})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evalutate Model Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_predictions(model, device, test_loader):\n",
    "    # Set model to eval mode to notify all layers.\n",
    "    model.eval()\n",
    "    \n",
    "    targets = []\n",
    "    preds = []\n",
    "    \n",
    "    # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loader:\n",
    "            data, target = sample\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Predict for data by doing forward pass\n",
    "            output = model(data.float())\n",
    "            pred = torch.round(output)\n",
    "            preds.append(pred.cpu().numpy())\n",
    "            targets.append(target.cpu().numpy())\n",
    "            \n",
    "    targets = [np.hstack(y) for y in targets]\n",
    "    preds = [np.hstack(y) for y in preds]\n",
    "    \n",
    "    targets = np.hstack(targets)\n",
    "    preds = np.hstack(preds)\n",
    "    \n",
    "    return targets, preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_true_baseline, y_pred_baseline = make_predictions(model, device, train_dataloader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_true, y_pred = make_predictions(model, device, test_dataloder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# y_true = [np.hstack(y) for y in y_true]\n",
    "# y_pred = [np.hstack(y) for y in y_pred]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# y_true = np.hstack(y_true)\n",
    "# y_pred = np.hstack(y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(y_true))\n",
    "print(len(y_pred))\n",
    "# Need to account for the [nx2] target vs the torch.max [nx1] pred.  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_cm(labels, predictions, p=0.5, num_classes=2):\n",
    "    cm = confusion_matrix(labels, predictions, labels=range(num_classes))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('True Negatives: ', cm[0][0])\n",
    "    print('False Positives: ', cm[0][1])\n",
    "    print('False Negatives: ', cm[1][0])\n",
    "    print('True Positives: ', cm[1][1])\n",
    "    print('Total Fraudulent: ', np.sum(cm[1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_cm(y_true, y_pred, num_classes=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot the ROC\n",
    "Now plot the ROC. This plot is useful because it shows, at a glance, the range of performance the model can reach just by tuning the output threshold."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from itertools import cycle\n",
    "def plot_roc_multiclass(name, labels, predictions, **kwargs):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = 2\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        y_test = (labels == i).astype(int)\n",
    "        y_pred = (predictions == i).astype(int)\n",
    "        fpr[i], tpr[i], _ = sklearn.metrics.roc_curve(y_test, y_pred)\n",
    "        roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
    "#         roc_display = sklearn.metrics.RocCurveDisplay(fpr=fpr[i], tpr=tpr[i]).plot()\n",
    "    \n",
    "    lw = 2\n",
    "    colors = cycle(['blue', 'red', 'green', 'purple'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw, label='No Skill')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (%)')\n",
    "    plt.ylabel('True Positive Rate (%)')\n",
    "    plt.title('Receiver operating characteristic for {} data'.format(name))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_roc_multiclass(\"Train\", y_true_baseline, y_pred_baseline)\n",
    "plot_roc_multiclass(\"Test\", y_true,  y_pred, linestyle='--')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_pr_multiclass(name, labels, predictions, **kwargs):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thresholds = dict()\n",
    "    mAP = dict()\n",
    "    n_classes = 2\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        y_test = (labels == i).astype(int)\n",
    "        y_pred = (predictions == i).astype(int)\n",
    "        precision[i], recall[i], thresholds[i] = sklearn.metrics.precision_recall_curve(y_test, y_pred)\n",
    "        mAP[i] = sklearn.metrics.average_precision_score(y_test, y_pred)\n",
    "#         pr_display = sklearn.metrics.PrecisionRecallDisplay(precision=precision[i], recall=recall[i]).plot()\n",
    "        \n",
    "    lw = 2\n",
    "    colors = cycle(['blue', 'red', 'green', 'purple'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(recall[i], precision[i], color=color, lw=lw,\n",
    "                 label='Percision-Recall curve class {0} (mAP = {1:0.2f})'.format(i, mAP[i]))\n",
    "\n",
    "    no_skill = len(labels[labels==1]) / len(labels)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], 'k--', linestyle='--', label='No Skill')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Percision')\n",
    "    plt.title('Percision-Recall Curve for {} data'.format(name))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_pr_multiclass(\"Train\",  y_true_baseline, y_pred_baseline)\n",
    "plot_pr_multiclass(\"Test\",  y_true,  y_pred, linestyle='--')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pyNMDR': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "2f14e27827fdc3f4954f75920519b89ca9bd10c317e580775133cd610938ce97"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}