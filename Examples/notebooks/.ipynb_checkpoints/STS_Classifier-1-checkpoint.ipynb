{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0b7be8-ef20-4eb0-a527-8f9ac8dbdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02337ff3-743d-4fb6-91fc-e9e249bea9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01dc48a-890d-4279-aac0-4b8fdd41a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38fccb2c-942f-4558-86d6-0f22b01a1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bfc0e0-b5bc-4813-90f6-af69a84285fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier.models import ConvNet1D\n",
    "from classifier.datasets import STSDataset\n",
    "from classifier.run import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159f63f5-1d8c-4ed4-b016-57b15cb2acb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'au_fcc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root = 'G:\\\\Research\\\\AI_STM\\\\gpspec\\\\dpath\\\\train\\\\'\n",
    "# os.listdir(root)\n",
    "# paths = glob.glob(os.path.join(root, \"**/*.npy\"), recursive = True)\n",
    "# paths = np.array(paths)\n",
    "# idxs = [1,5,6]\n",
    "# x = paths[idxs][0]\n",
    "# x[-26:-20]\n",
    "p=Path('G:\\\\Research\\\\AI_STM\\\\gpspec\\\\dpath\\\\train\\\\au_fcc\\\\dI_dV00008_Au_3.npy')\n",
    "p.parts[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcf54a-fa24-443c-89d6-587cc7dcc84d",
   "metadata": {},
   "source": [
    "# Define Custom Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f1ac84-73de-448d-a1cc-d871e83089e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class STSDataset(Dataset):\n",
    "#     def __init__(self, data_path, transform=None, target_transform=None):\n",
    "#         # get all filenames in root with filetype .npy\n",
    "#         self.data_root =  os.path.join(data_path, \"**/*.npy\")\n",
    "#         self.data_paths = glob.glob(self.data_root,\n",
    "#                                     recursive = True)\n",
    "#         self.data_paths = np.array(self.data_paths)\n",
    "        \n",
    "#         # get classes from directory structure\n",
    "#         self.targets = os.listdir(data_path)\n",
    "#         self.num_classes = len(self.targets)\n",
    "        \n",
    "#         # get number of samples\n",
    "#         self.n = len(self.data_paths)\n",
    "        \n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "        \n",
    "#         # get filepath using indexes \n",
    "#         sts_path = self.data_paths[idx]\n",
    "        \n",
    "#         # Get sts sample class from path\n",
    "#         label = Path(sts_path).parts[-2]\n",
    "        \n",
    "#         # Convert label to index\n",
    "#         label_i = self.targets.index(label)\n",
    "        \n",
    "#         # Use index to set active bit of onehot vector\n",
    "#         label_onehot = np.zeros(self.num_classes)\n",
    "#         label_onehot[label_i] = 1\n",
    "        \n",
    "#         # Read STS data from disk\n",
    "#         sts = np.load(sts_path)\n",
    "        \n",
    "#         # data has dI/dV and V with shape (2, 1200)\n",
    "#         # only use dI/dV\n",
    "#         sts = sts[0].copy().reshape( 1, -1)\n",
    "        \n",
    "#         if self.transform:\n",
    "#             sts = self.transform(sts)\n",
    "#         if self.target_transform:\n",
    "#             label_onehot = self.target_transform(label_onehot)\n",
    "            \n",
    "#         return torch.tensor(sts, dtype=float),  torch.tensor(label_i, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396901ab-927f-43c3-acb9-d2e0e97200ce",
   "metadata": {},
   "source": [
    "# Define Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d07242-ed14-4c68-bf1f-52c24c1a15cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class ConvNet(nn.Module):\n",
    "\n",
    "#     def __init__(self, n, num_classes, debug=False):\n",
    "#         super().__init__()\n",
    "#         self.debug = debug\n",
    "#         self.num_classes = num_classes\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1,\n",
    "#                                out_channels=64, \n",
    "#                                kernel_size=3, \n",
    "#                                stride=1)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=64,\n",
    "#                        out_channels=128, \n",
    "#                        kernel_size=3, \n",
    "#                        stride=1)\n",
    "#         self.maxpool = nn.MaxPool1d(3, stride=2)\n",
    "#         self.dropout = nn.Dropout(p=0.5)\n",
    "#         self.fc1 = nn.Linear(597, num_classes)\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         if self.debug: print(x.shape)\n",
    "\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         if self.debug: print(x.shape)\n",
    "        \n",
    "#         x = self.maxpool(x)\n",
    "#         if self.debug: print(x.shape)\n",
    "            \n",
    "#         x = self.dropout(x)\n",
    "#         if self.debug: print(x.shape)\n",
    "            \n",
    "#         x = self.fc1(x)\n",
    "#         if self.debug: print(x.shape)\n",
    "        \n",
    "#         # Remove unnecessary dimensions and change shape to match target tensor\n",
    "#         # [BATCH_SIZE, num_classes, 1, 1] --> [BATCH_SIZE,num_classes] to make predicitons\n",
    "# #         output = torch.squeeze(x)\n",
    "#         output = torch.reshape(x, (-1, self.num_classes))\n",
    "#         if self.debug: print(\"output:\\t\", output.shape)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ac65c-db27-4e90-8ff7-c91a0a0fd4a4",
   "metadata": {},
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3f367c-63e3-4709-b9db-d3eeba197486",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def progbar(curr, total, full_progbar, accuracy):\n",
    "#     frac = curr/total\n",
    "#     filled_progbar = round(frac*full_progbar)\n",
    "#     print('\\r', \n",
    "#           '#'*filled_progbar + '-'*(full_progbar-filled_progbar), \n",
    "#           '[{:>7.2%}]'.format(frac), \n",
    "#           'Accuracy: [{:>7.2%}]'.format(accuracy),\n",
    "#           end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9d0d65-f124-4bfd-8e46-789726497117",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_cats):\n",
    "#     '''\n",
    "#     Trains the model for an epoch and optimizes it.\n",
    "#     model: The model to train. Should already be in correct device.\n",
    "#     device: 'cuda' or 'cpu'.\n",
    "#     train_loader: dataloader for training samples.\n",
    "#     optimizer: optimizer to use for model parameter updates.\n",
    "#     criterion: used to compute loss for prediction and target \n",
    "#     epoch: Current epoch to train for.\n",
    "#     batch_size: Batch size to be used.\n",
    "#     '''\n",
    "    \n",
    "#     # Set model to train mode before each epoch\n",
    "#     model.train()\n",
    "    \n",
    "#     # Empty list to store losses \n",
    "#     losses = []\n",
    "#     correct = 0\n",
    "    \n",
    "#     # Iterate over entire training samples (1 epoch)\n",
    "#     for batch_idx, batch_sample in enumerate(train_loader):\n",
    "#         data, target = batch_sample\n",
    "\n",
    "#         # Push data/label to correct device\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "\n",
    "#         # Reset optimizer gradients. Avoids grad accumulation (accumulation used in RNN).\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Do forward pass for current set of data\n",
    "#         output = model(data.float())\n",
    "        \n",
    "#         # Compute loss based on criterion\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         # Computes gradient based on final loss\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Store loss\n",
    "#         losses.append(loss.item())\n",
    "        \n",
    "#         # Optimize model parameters based on learning rate and gradient \n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Get predicted class by rounding \n",
    "#         pred = output.round()\n",
    "#         pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "#         # Count correct predictions overall \n",
    "#         # Get element-wise equality between the preds and the targets for this batch,\n",
    "#         # finally sum the equalities and convert to a python float\n",
    "#         n_equal = pred.eq(target).sum().item()\n",
    "#         correct += n_equal\n",
    "\n",
    "#         # Update progress bar\n",
    "#         batch_accuracy = n_equal / torch.numel(target)\n",
    "#         progbar(batch_idx, len(train_loader), 10, batch_accuracy)\n",
    "    \n",
    "#     train_loss = float(np.mean(losses))\n",
    "#     train_acc = 100. * correct / ((batch_idx+1) * batch_size * num_cats)\n",
    "    \n",
    "#     print('\\nTrain set\\t Average loss: {:.4f}\\t Average Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "#         train_loss, correct, (batch_idx+1) * batch_size * num_cats, train_acc))\n",
    "          \n",
    "#     return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac438cd-5445-438e-8594-1acd313e5726",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test(model, device, test_loader, criterion, num_cats):\n",
    "#     '''\n",
    "#     Tests the model.\n",
    "#     model: The model to train. Should already be in correct device.\n",
    "#     device: 'cuda' or 'cpu'.\n",
    "#     test_loader: dataloader for test samples.\n",
    "#     '''\n",
    "    \n",
    "#     # Set model to eval mode to notify all layers.\n",
    "#     model.eval()\n",
    "    \n",
    "#     losses = []\n",
    "#     correct = 0\n",
    "    \n",
    "#     # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, sample in enumerate(test_loader):\n",
    "#             data, target = sample\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "                \n",
    "#             # Predict for data by doing forward pass\n",
    "#             output = model(data.float())\n",
    "            \n",
    "#             # Compute loss based on same criterion as training\n",
    "#             loss = criterion(output, target)\n",
    "\n",
    "#             # Append loss to overall test loss\n",
    "#             losses.append(loss.item())\n",
    "\n",
    "#             # Get predicted class by rounding \n",
    "#             pred = output.round()\n",
    "#             pred = torch.argmax(pred, dim=1)\n",
    "            \n",
    "#             # Count correct predictions overall \n",
    "#             # Get element-wise equality between the preds and the targets for this batch,\n",
    "#             # finally sum the equalities and convert to a std python float\n",
    "#             n_equal = pred.eq(target).sum().item()\n",
    "#             correct += n_equal\n",
    "\n",
    "#     test_loss = float(np.mean(losses))\n",
    "#     test_acc = (100. * correct) / (len(test_loader.dataset) * num_cats)\n",
    "#     print('Test set\\t Average loss: {:.4f}\\t Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset) * num_cats, test_acc))\n",
    "    \n",
    "#     return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1043b5-3a35-498b-a216-408b73b61fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device selected:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Set proper device based on cuda availability \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Torch device selected: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d71aa9-bf2f-41d7-a754-dca712b8244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'G:\\\\Research\\\\AI_STM\\\\gpspec\\\\dpath\\\\'\n",
    "train_path = data_path + 'train\\\\'\n",
    "val_path = data_path + 'validation\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c2422-7e96-4e05-8287-733747cead4f",
   "metadata": {},
   "source": [
    "# Create train and val subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33d2c7e3-5420-4069-8234-9b96329a2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformations to apply to each data sample \n",
    "# Can specify variations such as image flip, color flip, random crop, ...\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((1,1200)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c411d47-2527-4832-8130-904b768beecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_trainset = STSDataset(data_path=train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709d8176-0b20-4ee1-a5c0-27fa8548a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_valset = STSDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d3260ee-3855-414e-95d0-74565aa35f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(len(sts_valset)))\n",
    "test_split = 0.4\n",
    "val_idx, test_idx = train_test_split(idxs, test_size=test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20dfc98f-b75d-4a2c-b4ba-b91beb069f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 118\n"
     ]
    }
   ],
   "source": [
    "print(len(val_idx), len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65e7aa63-d852-4d84-b701-7ebdb0ada399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_valset = Subset(sts_valset, val_idx)\n",
    "sts_testset = Subset(sts_valset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9692e8b3-83ca-4bc6-be41-6df25e5b8e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 118\n"
     ]
    }
   ],
   "source": [
    "print(len(sts_valset), len(sts_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fc41bca-fb2f-45c7-9a5b-21aa04f540cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "# for i in range(len(sts_trainset)):\n",
    "#     sts, label = sts_trainset[i]\n",
    "#     print(i, sts.shape, label)\n",
    "\n",
    "#     ax = plt.subplot(1, 4, i + 1)\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     sample = sts.numpy()\n",
    "#     plt.plot(sample)\n",
    "\n",
    "#     if i == 3:\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827b0f0-4026-4ccb-b05f-c7279132ff74",
   "metadata": {},
   "source": [
    "# Preparing data for training with DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34efe797-35e9-4117-9c74-a13917a7f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(sts_trainset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(sts_valset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(sts_testset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d0509f8-6ef5-44e4-92ef-6f2d272ee0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 12 8\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader), len(val_dataloader), len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d64ff-bb79-4343-bd39-1f709f40bc9f",
   "metadata": {},
   "source": [
    "### Test iteration through the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be74c8dd-b8ac-4c66-ae2b-f10899ab279e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7.3208e-13, 7.6378e-13, 8.0791e-13,  ..., 9.9222e-13, 1.0362e-12,\n",
       "          1.0684e-12]], dtype=torch.float64),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts, label = next(iter(train_dataloader))\n",
    "sts_trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f43d5ca-c843-4970-a345-13baba51cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_dataloader))\n",
    "# for x in test_dataloader:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b5f6f58-f320-45bb-bb1e-d3fee84baa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sts, label = next(iter(test_dataloader))\n",
    "# sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4728104f-4e12-4b77-93e8-268534f48b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes of 1 points\n",
      "ConvNet1D(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "  (maxpool1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(128, 1, kernel_size=(3,), stride=(1,))\n",
      "  (maxpool2): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=297, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "n = len(sts_trainset[0][0])\n",
    "print(f'{num_classes} classes of {n} points')\n",
    "model = ConvNet1D(n=n, num_classes=num_classes, debug=False).to(device)\n",
    "EPOCHS = 10 \n",
    "learning_rate = 0.001\n",
    "BATCH_SIZE = 16\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d16ec317-ab0c-4370-b6dd-ee267df8620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "train_losses = np.zeros(EPOCHS)\n",
    "train_accuracies = np.zeros(EPOCHS)\n",
    "val_losses = np.zeros(EPOCHS)\n",
    "val_accuracies = np.zeros(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c642cc68-32f8-4715-b0de-9a782fd0127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ---------- [  0.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ---------- [  1.33%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ---------- [  2.67%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ---------- [  4.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [  5.33%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [  6.67%] Accuracy: [ 12.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [  8.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [  9.33%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [ 10.67%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [ 12.00%] Accuracy: [ 43.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [ 13.33%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #--------- [ 14.67%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ##-------- [ 16.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ##-------- [ 17.33%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ##-------- [ 18.67%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ##-------- [ 20.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ##-------- [ 21.33%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ##-------- [ 22.67%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ##-------- [ 24.00%] Accuracy: [ 43.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 25.33%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 26.67%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 28.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 29.33%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 30.67%] Accuracy: [ 43.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 32.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 33.33%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ###------- [ 34.67%] Accuracy: [ 43.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ####------ [ 36.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ####------ [ 37.33%] Accuracy: [ 43.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ####------ [ 38.67%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ####------ [ 40.00%] Accuracy: [ 12.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ####------ [ 41.33%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ####------ [ 42.67%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ####------ [ 44.00%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 45.33%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 46.67%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 48.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 49.33%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 50.67%] Accuracy: [  6.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 52.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 53.33%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #####----- [ 54.67%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ######---- [ 56.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ######---- [ 57.33%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ######---- [ 58.67%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ######---- [ 60.00%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ######---- [ 61.33%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ######---- [ 62.67%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ######---- [ 64.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 65.33%] Accuracy: [ 43.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 66.67%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 68.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 69.33%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 70.67%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 72.00%] Accuracy: [ 50.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 73.33%] Accuracy: [ 37.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #######--- [ 74.67%] Accuracy: [ 12.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########-- [ 76.00%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########-- [ 77.33%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########-- [ 78.67%] Accuracy: [ 12.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########-- [ 80.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########-- [ 81.33%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########-- [ 82.67%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########-- [ 84.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 85.33%] Accuracy: [ 25.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 86.67%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 88.00%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 89.33%] Accuracy: [ 31.25%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 90.67%] Accuracy: [ 18.75%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 92.00%] Accuracy: [ 50.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 93.33%] Accuracy: [ 12.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " #########- [ 94.67%] Accuracy: [ 12.50%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########## [ 96.00%] Accuracy: [ 50.00%]torch.Size([16, 64, 1198])\n",
      "torch.Size([16, 128, 1196])\n",
      "torch.Size([16, 128, 597])\n",
      "torch.Size([16, 1, 595])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 297])\n",
      "torch.Size([16, 1, 4])\n",
      "output:\t torch.Size([16, 4])\n",
      " ########## [ 97.33%] Accuracy: [ 31.25%]torch.Size([3, 64, 1198])\n",
      "torch.Size([3, 128, 1196])\n",
      "torch.Size([3, 128, 597])\n",
      "torch.Size([3, 1, 595])\n",
      "torch.Size([3, 1, 297])\n",
      "torch.Size([3, 1, 297])\n",
      "torch.Size([3, 1, 4])\n",
      "output:\t torch.Size([3, 4])\n",
      " ########## [ 98.67%] Accuracy: [  0.00%]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-260783679318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     train_loss, train_accuracy = train(model, device, \n\u001b[0m\u001b[0;32m      4\u001b[0m                                            \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                            \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\Research\\AI\\STM-AI\\Code\\classifier\\run.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, optimizer, criterion, epoch, batch_size, num_cats)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_cats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    train_loss, train_accuracy = train(model, device, \n",
    "                                           train_dataloader, \n",
    "                                           optimizer, criterion, \n",
    "                                           epoch, BATCH_SIZE, \n",
    "                                           num_classes)\n",
    "    val_loss, val_accuracy = test(model, device, \n",
    "                                    val_dataloader, \n",
    "                                    criterion, num_classes)\n",
    "\n",
    "    # Store epoch metrics in memory\n",
    "    i = epoch - 1\n",
    "    train_losses[i] = train_loss\n",
    "    train_accuracies[i] = train_accuracy\n",
    "    val_losses[i] = val_loss\n",
    "    val_accuracies[i] = val_accuracy\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        \n",
    "# Print final results to console\n",
    "print(\"best accuracy was {:2.2f}\".format(best_accuracy))\n",
    "print(\"Training and evaluation finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9acfe9b-132d-4b02-bd33-c5d8101e951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    for n, metric in enumerate(['loss', 'accuracy']):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,3,n+1)\n",
    "        plt.plot(metrics[metric], label='Train')\n",
    "        plt.plot(metrics['val_'+metric], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        plt.autoscale()\n",
    "        plt.legend()\n",
    "        plt.title(\"Standardized Data\")\n",
    "        \n",
    "    plt.autoscale()\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf9ef33-ad5b-4d8b-b0e2-6af790960de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics({\n",
    "    \"loss\": train_losses, \n",
    "    \"accuracy\": train_accuracies, \n",
    "    \"val_loss\": val_losses, \n",
    "    \"val_accuracy\": val_accuracies\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1594e8-8e69-45aa-a537-be6051e82f79",
   "metadata": {},
   "source": [
    "# Evalutate Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7a5d0-313e-4484-ad70-e92ed3b6d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, device, test_loader):\n",
    "    # Set model to eval mode to notify all layers.\n",
    "    model.eval()\n",
    "    \n",
    "    targets = []\n",
    "    preds = []\n",
    "    \n",
    "    # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loader:\n",
    "            data, target = sample\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Predict for data by doing forward pass\n",
    "            output = model(data.float())\n",
    "            pred = torch.round(output)\n",
    "            preds.append(pred.cpu().numpy())\n",
    "            targets.append(target.cpu().numpy())\n",
    "            \n",
    "    targets = [np.hstack(y) for y in targets]\n",
    "    preds = [np.hstack(y) for y in preds]\n",
    "    \n",
    "    targets = np.hstack(targets)\n",
    "    preds = np.hstack(preds)\n",
    "    \n",
    "    return targets, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b6efe-5d65-4f4e-9847-89b621026ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_baseline, y_pred_baseline = make_predictions(model, device, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766cca4-20e1-422d-9f1e-4b7d35574486",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = make_predictions(model, device, test_dataloder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538426e7-29f3-4fa3-89c6-3aef8fd1acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = [np.hstack(y) for y in y_true]\n",
    "# y_pred = [np.hstack(y) for y in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d549eb-d416-4558-9b65-01d2c60eefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = np.hstack(y_true)\n",
    "# y_pred = np.hstack(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ed8c1-a745-48b9-b3ea-142ef37611d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_true))\n",
    "print(len(y_pred))\n",
    "# Need to account for the [nx2] target vs the torch.max [nx1] pred.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08400ca9-1ccf-4f35-9508-88bd151908f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5, num_classes=2):\n",
    "    cm = confusion_matrix(labels, predictions, labels=range(num_classes))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('True Negatives: ', cm[0][0])\n",
    "    print('False Positives: ', cm[0][1])\n",
    "    print('False Negatives: ', cm[1][0])\n",
    "    print('True Positives: ', cm[1][1])\n",
    "    print('Total Fraudulent: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bd890-d47f-4707-af99-e22b9e242ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_true, y_pred, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785dce0-3559-41c4-bb0a-601afaa08136",
   "metadata": {},
   "source": [
    "## Plot the ROC\n",
    "Now plot the ROC. This plot is useful because it shows, at a glance, the range of performance the model can reach just by tuning the output threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71068a-f0cc-4db5-ba4e-6cb61b5f9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77126023-960a-4efa-a9cc-05c7771adaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "def plot_roc_multiclass(name, labels, predictions, **kwargs):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = 2\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        y_test = (labels == i).astype(int)\n",
    "        y_pred = (predictions == i).astype(int)\n",
    "        fpr[i], tpr[i], _ = sklearn.metrics.roc_curve(y_test, y_pred)\n",
    "        roc_auc[i] = sklearn.metrics.auc(fpr[i], tpr[i])\n",
    "#         roc_display = sklearn.metrics.RocCurveDisplay(fpr=fpr[i], tpr=tpr[i]).plot()\n",
    "    \n",
    "    lw = 2\n",
    "    colors = cycle(['blue', 'red', 'green', 'purple'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw, label='No Skill')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (%)')\n",
    "    plt.ylabel('True Positive Rate (%)')\n",
    "    plt.title('Receiver operating characteristic for {} data'.format(name))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf62228-4ef6-423d-8198-00b83728ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_multiclass(\"Train\", y_true_baseline, y_pred_baseline)\n",
    "plot_roc_multiclass(\"Test\", y_true,  y_pred, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f021bb-bead-4a86-9882-2d22273d6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_pr_multiclass(name, labels, predictions, **kwargs):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thresholds = dict()\n",
    "    mAP = dict()\n",
    "    n_classes = 2\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        y_test = (labels == i).astype(int)\n",
    "        y_pred = (predictions == i).astype(int)\n",
    "        precision[i], recall[i], thresholds[i] = sklearn.metrics.precision_recall_curve(y_test, y_pred)\n",
    "        mAP[i] = sklearn.metrics.average_precision_score(y_test, y_pred)\n",
    "#         pr_display = sklearn.metrics.PrecisionRecallDisplay(precision=precision[i], recall=recall[i]).plot()\n",
    "        \n",
    "    lw = 2\n",
    "    colors = cycle(['blue', 'red', 'green', 'purple'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(recall[i], precision[i], color=color, lw=lw,\n",
    "                 label='Percision-Recall curve class {0} (mAP = {1:0.2f})'.format(i, mAP[i]))\n",
    "\n",
    "    no_skill = len(labels[labels==1]) / len(labels)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], 'k--', linestyle='--', label='No Skill')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Percision')\n",
    "    plt.title('Percision-Recall Curve for {} data'.format(name))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bd8f3-3de0-485f-bae9-4b4d3fd66360",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_multiclass(\"Train\",  y_true_baseline, y_pred_baseline)\n",
    "plot_pr_multiclass(\"Test\",  y_true,  y_pred, linestyle='--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
